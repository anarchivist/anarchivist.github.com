<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistics on Mark A. Matienzo</title>
    <link>https://matienzo.org/tags/statistics/</link>
    <description>Recent content in statistics on Mark A. Matienzo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Feb 2009 23:28:03 +0000</lastBuildDate>
    
	<atom:link href="https://matienzo.org/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Developing Metrics for Experimental Forms of Outreach</title>
      <link>https://matienzo.org/2009/developing-metrics-for-experimental-forms-of-outreach/</link>
      <pubDate>Mon, 16 Feb 2009 23:28:03 +0000</pubDate>
      
      <guid>https://matienzo.org/2009/developing-metrics-for-experimental-forms-of-outreach/</guid>
      <description>ArchivesNext recently inquired about how archivists measure success of 2.0 initiatives. It&#39;s hard to determine some 2.0-ish initiatives will really impact statistics when you don&#39;t really define what the results you&#39;re trying to see. I&#39;d like to open the question further — how do we begin developing metrics for things that sit on the cusp between forms of outreach? Furthermore, I&#39;m curious to see where this information is captured — do archivists wait until the end to gather survey data, or if they working towards something like we at NYPL Labs are doing with Infomaki, our new usability tool developed by Michael Lascarides, our user analyst.</description>
    </item>
    
  </channel>
</rss>